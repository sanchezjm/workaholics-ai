langchain4j:
  local-ai:
    chat-model:
    base-url: http://localhost:8080
    model-name: codellama-7b
    temperature: 0.0
    timeout: PT60S

logging.level.dev.langchain4j: DEBUG
